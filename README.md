# ğŸš´â€â™‚ï¸ CitiBikes NYC Data Platform (Fabric Lakehouse Project)

This repository contains the full implementation of a modern **CitiBike NYC Lakehouse**, designed and built using **Microsoft Fabric**, **Delta Lake**, and **Kimball Data Modeling** principles.

> ğŸ“ Project Title: `Citibikes-Integration`  
> ğŸ§± Architecture: Medallion (Bronze â†’ Silver â†’ Gold)  
> ğŸ“Š Modeling: Dimensional (Star Schema)  
> â˜ï¸ Platform: Microsoft Fabric (Lakehouse, Pipelines, Notebooks)

---

## ğŸ“ Project Structure

```bash
â”œâ”€â”€ ingestion/           # Raw data ingestion logic (bronze layer)
â”œâ”€â”€ pipelines/           # Fabric Data Pipelines for orchestration
â”œâ”€â”€ utils/               # Reusable helper functions & constants
â”œâ”€â”€ dimfact/             # Dimensional modeling (dim/fact table logic)
â””â”€â”€ README.md            # Project overview and documentation

# ğŸš´ CitiBike NYC Fabric Lakehouse Project (`dimfact`)

This project demonstrates how to design and implement a modern **Lakehouse pipeline** using Microsoft Fabric with real-world data from the [NYC CitiBike Program](https://ride.citibikenyc.com/system-data).  
It uses Delta Lake, PySpark, and Fabric Pipelines to build a scalable ingestion + transformation workflow based on **dimensional modeling**.

---

## ğŸ“ Features
- âœ… **Incremental ingestion** using `input_file_name()` & `MERGE`
- âœ… **Metadata enrichment** (SourceSystem, IngestionDate, HASH_ID)
- âœ… **Data Quality Checks** (trip duration, valid station IDs)
- âœ… **Star Schema modeling** for BI consumption (dim/fact)

---

